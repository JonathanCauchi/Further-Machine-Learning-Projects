{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing and exploring the data using a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing our dataset. For this lab, we will use a subset of the data distributed for a Shared Task on sentiment analysis in tweets, conducted as part of <a href=\"http://alt.qcri.org/semeval2017/\">SemEval 2017</a>.\n",
    "\n",
    "We are interested in <a href=\"http://alt.qcri.org/semeval2017/task4/\">Semeval Task 4A</a>. For convenience, one part of the data has been provided for you for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'NiaveBayesDataset.txt' #Input file, tab-delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data has no header. Also, we only want the first 3 cols  -- see usecols argument\n",
    "#Some lines have a fourth (date) column\n",
    "data = pd.read_csv(input_file, sep='\\t', encoding=\"utf-8\", header=None, usecols=range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can name our own columns\n",
    "data.columns = ['ID', 'Polarity', 'Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Explore the data: head() and tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to explore the data using the following commands:\n",
    "* head()\n",
    "* tail()\n",
    "* finding a column by name, e.g. data['Polarity']\n",
    "* finding a specific row, by treating the data frame as you would a normal python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619950566786113536</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619969366986235905</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>619971047195045888</td>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>619974445185302528</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>619987808317407232</td>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Polarity  \\\n",
       "0  619950566786113536   neutral   \n",
       "1  619969366986235905   neutral   \n",
       "2  619971047195045888  negative   \n",
       "3  619974445185302528   neutral   \n",
       "4  619987808317407232  positive   \n",
       "\n",
       "                                               Tweet  \n",
       "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
       "1  Order Go Set a Watchman in store or through ou...  \n",
       "2  If these runway renovations at the airport pre...  \n",
       "3  If you could ask an onstage interview question...  \n",
       "4  A portion of book sales from our Harper Lee/Go...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>681877834982232064</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>681879579129200640</td>\n",
       "      <td>positive</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>681883903259357184</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>681904976860327936</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>681910549211287552</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  Polarity  \\\n",
       "20627  681877834982232064   neutral   \n",
       "20628  681879579129200640  positive   \n",
       "20629  681883903259357184   neutral   \n",
       "20630  681904976860327936  negative   \n",
       "20631  681910549211287552   neutral   \n",
       "\n",
       "                                                   Tweet  \n",
       "20627  @ShaquilleHoNeal from what I think you're aski...  \n",
       "20628  Iran ranks 1st in liver surgeries, Allah bless...  \n",
       "20629  Hours before he arrived in Saudi Arabia on Tue...  \n",
       "20630  @VanityFair  Alex Kim Kardashian worth how to ...  \n",
       "20631  I guess even Pandora knows Justin Bieber is a ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Explore the data distribution by plotting Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to explore the distribution of data. We are often working with highly skewed distributions. In real-world applications, we don't normally find values which are equally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use numpy to run a quick procedure over the 'Polarity' column in our data frame, to find the unique values (which should be three) and their corresponding frequencies. This returns a pair: the unique values and their counts, in separate lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Use numpy to find unique polarity vals and count them\n",
    "unique, counts = np.unique(data['Polarity'], return_counts=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new pandas dataframe, treating unique and counts as its columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create a temporary pandas frame with these values and frequencies\n",
    "polarities = pd.DataFrame({'polarity': unique, 'frequency': counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>10342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>7059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  frequency\n",
       "0  negative       3231\n",
       "1   neutral      10342\n",
       "2  positive       7059"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the values in the new dataframe. This uses a built-in plot() command, but we need to import the plot function from matplotlib first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1acd71447f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#and plot\n",
    "polarities.plot.bar(x='polarity', y='frequency', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into two disjoint sets, for training (90%) and for testing (10%). The function below needs to be completed, such that it takes a dataframe and a ratio for the training proportion (e.g. 0.9) and randomly splits the data accordingly. One possible strategy:\n",
    "1. collect the indices correaponding to all the rows in the DF \n",
    "2. shuffle them to create a random permutation using numpy\n",
    "3. take the first x% as the training indices, the rest for training\n",
    "4. use the convenient pandas iloc function to retrieve the rows for each set by their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, ratio):\n",
    "    train = data.iloc[0:round(len(data)*0.9)]\n",
    "    test = data.iloc[round(len(data)*0.9):]\n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way is to split using a built-in function in scikit-learn, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#random_state param is just a random number seed\n",
    "train, test = train_test_split(data, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>630134008718958592</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Miguel Montero with a go-ahead RBI single in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13485</th>\n",
       "      <td>640191552065658881</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Even maybe more odd is the Marion County judge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>630465779511771136</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Frank Gifford, who died today at 84, worked th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018</th>\n",
       "      <td>680634687463788544</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@Julienaticadiks: You can now Listen new song ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>633505111105409025</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@_alexisaguirre_ Not sure if you'd enjoy them,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID Polarity  \\\n",
       "4336   630134008718958592  neutral   \n",
       "13485  640191552065658881  neutral   \n",
       "4505   630465779511771136  neutral   \n",
       "20018  680634687463788544  neutral   \n",
       "6497   633505111105409025  neutral   \n",
       "\n",
       "                                                   Tweet  \n",
       "4336   Miguel Montero with a go-ahead RBI single in h...  \n",
       "13485  Even maybe more odd is the Marion County judge...  \n",
       "4505   Frank Gifford, who died today at 84, worked th...  \n",
       "20018  @Julienaticadiks: You can now Listen new song ...  \n",
       "6497   @_alexisaguirre_ Not sure if you'd enjoy them,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use sklearn to implement a classifier. Our strategy will be to:\n",
    "1. Extract the vocabulary from our training instances\n",
    "2. Vectorise our training instances using the Bag of Words assumption\n",
    "3. Initially we'll use word frequencies. So each document (each Tweet in our dataframe) becomes a list of numbers of length |V|, where, for each element of our vocabulary V, there is a corresponding number indicating the freqency of that word in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 The CountVectorizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A count vectorizer in sklearn is a class that transforms text into a vector of word features with their corresponding counts. The CountVEctorizer can apply a stop list (it's built in for English, so we can just tell it to use that one. But otherwise can be supplied as a list). See <a href=\"http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\">the documentation for more details on this class</a> and the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\">API reference</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "counter = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "\n",
    "#pass all tweets in the training set to the count vectoriser and apply 'fit_transform'\n",
    "train_features = counter.fit_transform(train['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18568x175925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 399129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a large, sparse matrix where each row corresponds to a tweet. Each column corresponds to one of the words in the vocab.\n",
    "You can convince yourself that this is the case by comparing the <b>shape</b> of the train array and the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18568, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18568, 175925)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a CountVectorizer matrix, columns correspond to words. We can see what words we have. You'll notice that there is a lot of noise, partly due to tweets containing urls etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '00 00p',\n",
       " '00 00pm',\n",
       " '00 05',\n",
       " '00 08',\n",
       " '00 10',\n",
       " '00 12',\n",
       " '00 13',\n",
       " '00 1st',\n",
       " '00 2nd',\n",
       " '00 30',\n",
       " '00 30pm',\n",
       " '00 amp',\n",
       " '00 bids',\n",
       " '00 brown',\n",
       " '00 buddha',\n",
       " '00 case',\n",
       " '00 centraleuropeantime',\n",
       " '00 cet',\n",
       " '00 ch4',\n",
       " '00 donation',\n",
       " '00 era',\n",
       " '00 hey',\n",
       " '00 hot',\n",
       " '00 http',\n",
       " '00 jan',\n",
       " '00 ken',\n",
       " '00 lydia',\n",
       " '00 meets',\n",
       " '00 mn',\n",
       " '00 mon',\n",
       " '00 newport',\n",
       " '00 old',\n",
       " '00 pm',\n",
       " '00 sam',\n",
       " '00 time',\n",
       " '00 uur',\n",
       " '00 voodoo',\n",
       " '00 yin',\n",
       " '00 yoga',\n",
       " '000',\n",
       " '000 000',\n",
       " '000 barrels',\n",
       " '000 candidates',\n",
       " '000 coins',\n",
       " '000 cops',\n",
       " '000 employees',\n",
       " '000 enjoyed',\n",
       " '000 fans',\n",
       " '000 fighters',\n",
       " '000 help',\n",
       " '000 https',\n",
       " '000 ilk',\n",
       " '000 innocents',\n",
       " '000 ira',\n",
       " '000 islamists',\n",
       " '000 jerry',\n",
       " '000 lamborghini',\n",
       " '000 legal',\n",
       " '000 muslims',\n",
       " '000 people',\n",
       " '000 spectators',\n",
       " '000 students',\n",
       " '000 things',\n",
       " '000 views',\n",
       " '000 women',\n",
       " '001',\n",
       " '001 940',\n",
       " '007',\n",
       " '007 film',\n",
       " '007 spectre',\n",
       " '00am',\n",
       " '00am 11',\n",
       " '00am christians',\n",
       " '00am live',\n",
       " '00am matthews',\n",
       " '00am new',\n",
       " '00am open',\n",
       " '00am pick',\n",
       " '00p',\n",
       " '00p yoga',\n",
       " '00pm',\n",
       " '00pm 30pm',\n",
       " '00pm 9th',\n",
       " '00pm armed',\n",
       " '00pm coors',\n",
       " '00pm dramatic',\n",
       " '00pm enjoy',\n",
       " '00pm gsc',\n",
       " '00pm http',\n",
       " '00pm paul',\n",
       " '00pm samples',\n",
       " '00pm super',\n",
       " '01',\n",
       " '01 26',\n",
       " '01 make',\n",
       " '01 seth',\n",
       " '01924',\n",
       " '01924 290870',\n",
       " '01m',\n",
       " '01m pixels',\n",
       " '02',\n",
       " '02 2016',\n",
       " '02 acad',\n",
       " '02 http',\n",
       " '02 otrabuffalo',\n",
       " '02 sep',\n",
       " '02 sept',\n",
       " '02 topical',\n",
       " '024yoesdgm',\n",
       " '024yoesdgm rollingstone',\n",
       " '02pqbxcg2w',\n",
       " '03',\n",
       " '03 06',\n",
       " '03 53',\n",
       " '03084455248',\n",
       " '03332386735',\n",
       " '038k9zoxov',\n",
       " '039',\n",
       " '039 girlfriend',\n",
       " '03ww4m3nqp',\n",
       " '04',\n",
       " '04 2015',\n",
       " '04 left',\n",
       " '04 remaining',\n",
       " '04 september',\n",
       " '04 want',\n",
       " '04an71l7hn',\n",
       " '04llfba03e',\n",
       " '04th',\n",
       " '04th today',\n",
       " '04uexsbx2q',\n",
       " '04zrtxszy4',\n",
       " '05',\n",
       " '05 09',\n",
       " '05 bed',\n",
       " '05 est',\n",
       " '05 pitch',\n",
       " '05 tee',\n",
       " '05 ucl',\n",
       " '052jgiqwvk',\n",
       " '05i80pwr4q',\n",
       " '05pm',\n",
       " '05pm showing',\n",
       " '06',\n",
       " '06 23',\n",
       " '06 finished',\n",
       " '06 thor',\n",
       " '06oilp9tr1',\n",
       " '07',\n",
       " '07 00',\n",
       " '07 11',\n",
       " '07 15',\n",
       " '07 burgoyne',\n",
       " '07 game',\n",
       " '07 nov',\n",
       " '07 october',\n",
       " '07 want',\n",
       " '08',\n",
       " '08 00',\n",
       " '08 09',\n",
       " '08 friday',\n",
       " '08 hats',\n",
       " '09',\n",
       " '09 10',\n",
       " '09 15',\n",
       " '09 28',\n",
       " '09 https',\n",
       " '09 lean',\n",
       " '09 nov',\n",
       " '0915',\n",
       " '0915 bbc2',\n",
       " '0966kas',\n",
       " '0966kas coz',\n",
       " '096q8eecc0',\n",
       " '09wpam7wh6',\n",
       " '09yjrefna5',\n",
       " '09zxe013f8',\n",
       " '0a6rbvqc9l',\n",
       " '0adxtgv1ri',\n",
       " '0ajhlefxar',\n",
       " '0amc0mdsha',\n",
       " '0b5eavru4q',\n",
       " '0bgabtay3p',\n",
       " '0bgabtay3p teachenglish',\n",
       " '0cd3jbknth',\n",
       " '0ci3gskleu',\n",
       " '0d69wqpvd9',\n",
       " '0d69wqpvd9 http',\n",
       " '0dv4heocvy',\n",
       " '0dv4heocvy https',\n",
       " '0dyljrpsmx',\n",
       " '0edfxsawhw',\n",
       " '0ewbjgjure',\n",
       " '0ffsxzymap',\n",
       " '0ftdlggkt7',\n",
       " '0hdszn5chx',\n",
       " '0hecetzwg9',\n",
       " '0hr5zp6ryu',\n",
       " '0hsi2cflkl',\n",
       " '0hu5p2eiul',\n",
       " '0hu5p2eiul yoga',\n",
       " '0iezqtinbn',\n",
       " '0ivuh9hhlj',\n",
       " '0ivuh9hhlj mlb',\n",
       " '0j3o93swwl',\n",
       " '0jvqrbq9bz',\n",
       " '0k4ms0u8go',\n",
       " '0kdh6f8dsy',\n",
       " '0lpmjwqtdw',\n",
       " '0ltlfitkip',\n",
       " '0ltzglsyk9',\n",
       " '0lvsrwwzml',\n",
       " '0m0pjvu9pz',\n",
       " '0mhukfackw',\n",
       " '0mmjf1klro',\n",
       " '0n5fcoohnb',\n",
       " '0ne',\n",
       " '0ne m0re',\n",
       " '0nfasgc94t',\n",
       " '0nfyut434f',\n",
       " '0njstrprjx',\n",
       " '0o2vqowrda',\n",
       " '0ogq1whwcg',\n",
       " '0ohnhbnhux',\n",
       " '0ombs8uwq8',\n",
       " '0ow0cc3q2g',\n",
       " '0p4f0g8nzh',\n",
       " '0p4f0g8nzh tv',\n",
       " '0p8uvrc6xo',\n",
       " '0pgtjpj6p8',\n",
       " '0qtaknz3hh',\n",
       " '0r6f3wblil',\n",
       " '0rgssz3j1b',\n",
       " '0rgssz3j1b wwe',\n",
       " '0syzfqcg7l',\n",
       " '0t402y1zps',\n",
       " '0t402y1zps twitterstorm',\n",
       " '0tguzzkua3',\n",
       " '0th',\n",
       " '0th time',\n",
       " '0tptx3v6um',\n",
       " '0udsnltbec',\n",
       " '0uhlgyg3u7',\n",
       " '0ve81uzovo',\n",
       " '0vtfunxls4',\n",
       " '0vxkhhgcij',\n",
       " '0vxkhhgcij yoga',\n",
       " '0vzbhbrfkm',\n",
       " '0w0votfvdj',\n",
       " '0w91odlx3n',\n",
       " '0w91odlx3n lovato',\n",
       " '0wfwzlbhbh',\n",
       " '0wydnfhlqb',\n",
       " '0x3oseqznr',\n",
       " '0x9kd0vm4b',\n",
       " '0xdt2a9gcm',\n",
       " '0xulqerqzn',\n",
       " '0y2llpytes',\n",
       " '0yeshp4i4d',\n",
       " '0ykehn4bz3',\n",
       " '0z4e8vop0l',\n",
       " '0z4e8vop0l rmas',\n",
       " '0zbvdhjgas',\n",
       " '0ztfmraru0',\n",
       " '10',\n",
       " '10 00',\n",
       " '10 000',\n",
       " '10 00am',\n",
       " '10 04',\n",
       " '10 10',\n",
       " '10 100',\n",
       " '10 11',\n",
       " '10 11am',\n",
       " '10 12',\n",
       " '10 15',\n",
       " '10 17',\n",
       " '10 1970',\n",
       " '10 19th',\n",
       " '10 2015',\n",
       " '10 2016',\n",
       " '10 30',\n",
       " '10 30am',\n",
       " '10 30mst',\n",
       " '10 30pm',\n",
       " '10 44',\n",
       " '10 45',\n",
       " '10 46',\n",
       " '10 49',\n",
       " '10 59',\n",
       " '10 8th',\n",
       " '10 alleged',\n",
       " '10 amp',\n",
       " '10 arabs',\n",
       " '10 asu',\n",
       " '10 august',\n",
       " '10 better',\n",
       " '10 boruto',\n",
       " '10 break',\n",
       " '10 candidates',\n",
       " '10 carlyfiorina',\n",
       " '10 check',\n",
       " '10 clock',\n",
       " '10 colto',\n",
       " '10 cool',\n",
       " '10 cornhole',\n",
       " '10 curtis',\n",
       " '10 dates',\n",
       " '10 day',\n",
       " '10 days',\n",
       " '10 debate',\n",
       " '10 dec',\n",
       " '10 december',\n",
       " '10 dj',\n",
       " '10 dudes',\n",
       " '10 english',\n",
       " '10 entry',\n",
       " '10 er',\n",
       " '10 fabriqmi',\n",
       " '10 faved',\n",
       " '10 female',\n",
       " '10 fishermen',\n",
       " '10 fly923',\n",
       " '10 fx',\n",
       " '10 game',\n",
       " '10 games',\n",
       " '10 gift',\n",
       " '10 global',\n",
       " '10 gop',\n",
       " '10 gucci',\n",
       " '10 help',\n",
       " '10 hit',\n",
       " '10 holes',\n",
       " '10 hour',\n",
       " '10 hours',\n",
       " '10 http',\n",
       " '10 huckabee',\n",
       " '10 iced',\n",
       " '10 inning',\n",
       " '10 innings',\n",
       " '10 jan',\n",
       " '10 jays',\n",
       " '10 jrtfootball',\n",
       " '10 live',\n",
       " '10 louis',\n",
       " '10 march',\n",
       " '10 mean',\n",
       " '10 million',\n",
       " '10 min',\n",
       " '10 mins',\n",
       " '10 minute',\n",
       " '10 minutes',\n",
       " '10 missing',\n",
       " '10 mom',\n",
       " '10 moments',\n",
       " '10 month',\n",
       " '10 murray',\n",
       " '10 musical',\n",
       " '10 naruto',\n",
       " '10 natfavebeatles',\n",
       " '10 nice',\n",
       " '10 non',\n",
       " '10 october',\n",
       " '10 pig',\n",
       " '10 play',\n",
       " '10 pm',\n",
       " '10 power106la',\n",
       " '10 preaching',\n",
       " '10 proclamationday',\n",
       " '10 randy',\n",
       " '10 rappers',\n",
       " '10 recall',\n",
       " '10 release',\n",
       " '10 republican',\n",
       " '10 republicans',\n",
       " '10 reuters',\n",
       " '10 reviews',\n",
       " '10 riverforestpl',\n",
       " '10 role',\n",
       " '10 running',\n",
       " '10 seasons',\n",
       " '10 seconds',\n",
       " '10 sept',\n",
       " '10 shirt',\n",
       " '10 shot',\n",
       " '10 shouldn',\n",
       " '10 shounen',\n",
       " '10 specific',\n",
       " '10 starting',\n",
       " '10 super',\n",
       " '10 tampa',\n",
       " '10 theopen',\n",
       " '10 theopen2015',\n",
       " '10 things',\n",
       " '10 think',\n",
       " '10 thor',\n",
       " '10 tied',\n",
       " '10 times',\n",
       " '10 timeshavechanged',\n",
       " '10 tomorrow',\n",
       " '10 tracks',\n",
       " '10 uk',\n",
       " '10 units',\n",
       " '10 vote',\n",
       " '10 weei',\n",
       " '10 weekend',\n",
       " '10 years',\n",
       " '10 yrs',\n",
       " '100',\n",
       " '100 000',\n",
       " '100 back2_the90s',\n",
       " '100 bats',\n",
       " '100 beer',\n",
       " '100 better',\n",
       " '100 boys',\n",
       " '100 cent',\n",
       " '100 coming',\n",
       " '100 committed',\n",
       " '100 convinced',\n",
       " '100 dec',\n",
       " '100 dm',\n",
       " '100 dollars',\n",
       " '100 edited',\n",
       " '100 fake',\n",
       " '100 finishes',\n",
       " '100 going',\n",
       " '100 got',\n",
       " '100 hit',\n",
       " '100 hope',\n",
       " '100 injured',\n",
       " '100 jacked',\n",
       " '100 level',\n",
       " '100 list',\n",
       " '100 louis',\n",
       " '100 million',\n",
       " '100 new',\n",
       " '100 pair',\n",
       " '100 peaked',\n",
       " '100 people',\n",
       " '100 piece',\n",
       " '100 pitches',\n",
       " '100 release',\n",
       " '100 rts',\n",
       " '100 seats',\n",
       " '100 section',\n",
       " '100 soldier',\n",
       " '100 sony',\n",
       " '100 strong',\n",
       " '100 sure',\n",
       " '100 thursday',\n",
       " '100 true',\n",
       " '100 visa',\n",
       " '100 voters',\n",
       " '100 yards',\n",
       " '100 years',\n",
       " '1000',\n",
       " '1000 civilians',\n",
       " '1000 enter',\n",
       " '1000 people',\n",
       " '1000 sat',\n",
       " '1000 soldiers',\n",
       " '1000 suns',\n",
       " '10000',\n",
       " '10000 sure',\n",
       " '100bn',\n",
       " '100bn gonna',\n",
       " '100days',\n",
       " '100days promised',\n",
       " '100facts',\n",
       " '100facts 76',\n",
       " '100m',\n",
       " '100m views',\n",
       " '100numbertwos50s60s',\n",
       " '100numbertwos50s60s sep',\n",
       " '100s',\n",
       " '100s youth',\n",
       " '100th',\n",
       " '100th career',\n",
       " '100th episode',\n",
       " '100th strikeout',\n",
       " '100wasteddays',\n",
       " '101',\n",
       " '101 children',\n",
       " '101 happy',\n",
       " '101 http',\n",
       " '101 staff',\n",
       " '101 sure',\n",
       " '101wkqx',\n",
       " '101wkqx sabra',\n",
       " '102',\n",
       " '102 93',\n",
       " '102 days',\n",
       " '1025fenwayweekend',\n",
       " '1025sendmebackstage',\n",
       " '1025sendmebackstage shirt',\n",
       " '103',\n",
       " '103 10',\n",
       " '103 career',\n",
       " '103 event',\n",
       " '1037292947291',\n",
       " '1037292947291 time',\n",
       " '103758',\n",
       " '103822',\n",
       " '104',\n",
       " '104 mph',\n",
       " '1043',\n",
       " '1043 2nd',\n",
       " '1057wror',\n",
       " '106',\n",
       " '106 sun',\n",
       " '1075theriver',\n",
       " '1075theriver contest',\n",
       " '1075theriver ed',\n",
       " '108',\n",
       " '108 face',\n",
       " '108 jorit',\n",
       " '1080',\n",
       " '1080 lyrics',\n",
       " '109',\n",
       " '109 pitches',\n",
       " '1099',\n",
       " '1099 jerusalem',\n",
       " '10a',\n",
       " '10a amp',\n",
       " '10am',\n",
       " '10am 11am',\n",
       " '10am 2pm',\n",
       " '10am 4pm',\n",
       " '10am 5pm',\n",
       " '10am 6pm',\n",
       " '10am 8pm',\n",
       " '10am breath',\n",
       " '10am cet',\n",
       " '10am dunkin',\n",
       " '10am est',\n",
       " '10am https',\n",
       " '10am let',\n",
       " '10am ll',\n",
       " '10am need',\n",
       " '10am noon',\n",
       " '10am ron',\n",
       " '10am saturday',\n",
       " '10am therapeutic',\n",
       " '10am tomorrow',\n",
       " '10inthehole',\n",
       " '10inthehole 8th',\n",
       " '10k',\n",
       " '10k naruto',\n",
       " '10million',\n",
       " '10million stg',\n",
       " '10mins',\n",
       " '10mins kane',\n",
       " '10p',\n",
       " '10p et',\n",
       " '10pm',\n",
       " '10pm come',\n",
       " '10pm sat',\n",
       " '10pm school',\n",
       " '10pm sogh',\n",
       " '10pm watch',\n",
       " '10th',\n",
       " '10th 10',\n",
       " '10th 11th',\n",
       " '10th 12th',\n",
       " '10th 17th',\n",
       " '10th 1pm',\n",
       " '10th 1st',\n",
       " '10th 50',\n",
       " '10th africa',\n",
       " '10th allow',\n",
       " '10th amend',\n",
       " '10th amendment',\n",
       " '10th amp',\n",
       " '10th anniv',\n",
       " '10th anniversary',\n",
       " '10th auction',\n",
       " '10th aug',\n",
       " '10th ball',\n",
       " '10th bc',\n",
       " '10th beat',\n",
       " '10th beautiful',\n",
       " '10th blue',\n",
       " '10th career',\n",
       " '10th centuries',\n",
       " '10th cometogether',\n",
       " '10th crazy',\n",
       " '10th currently',\n",
       " '10th curtis',\n",
       " '10th danny',\n",
       " '10th day',\n",
       " '10th declared',\n",
       " '10th degree',\n",
       " '10th demon',\n",
       " '10th drug',\n",
       " '10th ed',\n",
       " '10th final',\n",
       " '10th game',\n",
       " '10th gop',\n",
       " '10th grade',\n",
       " '10th graders',\n",
       " '10th hole',\n",
       " '10th http',\n",
       " '10th https',\n",
       " '10th inning',\n",
       " '10th insane',\n",
       " '10th jason',\n",
       " '10th kind',\n",
       " '10th list',\n",
       " '10th master',\n",
       " '10th means',\n",
       " '10th metal',\n",
       " '10th muharram',\n",
       " '10th nakama',\n",
       " '10th october',\n",
       " '10th outright',\n",
       " '10th past',\n",
       " '10th paul',\n",
       " '10th pick',\n",
       " '10th polls',\n",
       " '10th ps4',\n",
       " '10th qb',\n",
       " '10th rangers',\n",
       " '10th rbi',\n",
       " '10th reality',\n",
       " '10th really',\n",
       " '10th round',\n",
       " '10th seeing',\n",
       " '10th skin',\n",
       " '10th slot',\n",
       " '10th sort',\n",
       " '10th sports',\n",
       " '10th spot',\n",
       " '10th st',\n",
       " '10th start',\n",
       " '10th states',\n",
       " '10th steelers',\n",
       " '10th sytycd',\n",
       " '10th thanks',\n",
       " '10th time',\n",
       " '10th told',\n",
       " '10th trailers',\n",
       " '10th twilight',\n",
       " '10th tx',\n",
       " '10th walk',\n",
       " '10th wedding',\n",
       " '10th white',\n",
       " '10th ww',\n",
       " '10th year',\n",
       " '10x',\n",
       " '10x influential',\n",
       " '10xlp',\n",
       " '10xlp boxset',\n",
       " '11',\n",
       " '11 00',\n",
       " '11 00am',\n",
       " '11 00pm',\n",
       " '11 11',\n",
       " '11 11pm',\n",
       " '11 12',\n",
       " '11 12th',\n",
       " '11 13',\n",
       " '11 15am',\n",
       " '11 16',\n",
       " '11 16th',\n",
       " '11 1st',\n",
       " '11 2014',\n",
       " '11 2015',\n",
       " '11 30',\n",
       " '11 30am',\n",
       " '11 30pm',\n",
       " '11 35',\n",
       " '11 3rd',\n",
       " '11 40',\n",
       " '11 45',\n",
       " '11 45pm',\n",
       " '11 4th',\n",
       " '11 999',\n",
       " '11 ac',\n",
       " '11 album',\n",
       " '11 bmth',\n",
       " '11 boston',\n",
       " '11 churcfofchrist',\n",
       " '11 clearly',\n",
       " '11 contact',\n",
       " '11 curtis',\n",
       " '11 day',\n",
       " '11 days',\n",
       " '11 dec',\n",
       " '11 december',\n",
       " '11 east',\n",
       " '11 et',\n",
       " '11 extras',\n",
       " '11 falling',\n",
       " '11 foundry',\n",
       " '11 going',\n",
       " '11 grammy',\n",
       " '11 grammys',\n",
       " '11 gucci',\n",
       " '11 hijackers',\n",
       " '11 hits',\n",
       " '11 hours',\n",
       " '11 http',\n",
       " '11 https',\n",
       " '11 hug',\n",
       " '11 inning',\n",
       " '11 innocent',\n",
       " '11 jordan',\n",
       " '11 mariners',\n",
       " '11 milan',\n",
       " '11 months',\n",
       " '11 new',\n",
       " '11 niagra',\n",
       " '11 nicki',\n",
       " '11 nominations',\n",
       " '11 noon',\n",
       " '11 north',\n",
       " '11 october',\n",
       " '11 ominously',\n",
       " '11 open',\n",
       " '11 originally',\n",
       " '11 people',\n",
       " '11 pitchs',\n",
       " '11 plane',\n",
       " '11 pm',\n",
       " '11 police',\n",
       " '11 reuters',\n",
       " '11 rising',\n",
       " '11 row',\n",
       " '11 rules',\n",
       " '11 sam',\n",
       " '11 sep',\n",
       " '11 shall',\n",
       " '11 skybet',\n",
       " '11 spieth',\n",
       " '11 starts',\n",
       " '11 strikeouts',\n",
       " '11 ted',\n",
       " '11 theater',\n",
       " '11 tied',\n",
       " '11 time',\n",
       " '11 times',\n",
       " '11 topical',\n",
       " '11 vs',\n",
       " '11 wearing',\n",
       " '11 white',\n",
       " '11 won',\n",
       " '11 work',\n",
       " '11 yankees',\n",
       " '11 year',\n",
       " '11 yes',\n",
       " '11 zach',\n",
       " '110',\n",
       " '110 countries',\n",
       " '110 song',\n",
       " '110pm',\n",
       " '110pm start',\n",
       " '111',\n",
       " '111 december',\n",
       " '111 yes',\n",
       " '111cr',\n",
       " '111cr http',\n",
       " '112',\n",
       " '112 appearances',\n",
       " '1178',\n",
       " '1178 https',\n",
       " '118th',\n",
       " '118th position',\n",
       " '11909',\n",
       " '11909 backed',\n",
       " '11am',\n",
       " '11am caracal',\n",
       " '11am est',\n",
       " '11am going',\n",
       " '11am http',\n",
       " '11am make',\n",
       " '11am outthere',\n",
       " '11am pc',\n",
       " '11am pst',\n",
       " '11am rsvp',\n",
       " '11am saturday',\n",
       " '11clubroom',\n",
       " '11clubroom https',\n",
       " '11k',\n",
       " '11k 1er',\n",
       " '11ks',\n",
       " '11ks wins',\n",
       " '11mo',\n",
       " '11mo ago',\n",
       " '11pm',\n",
       " '11pm 2am',\n",
       " '11pm 4am',\n",
       " '11pm s2',\n",
       " '11th',\n",
       " '11th 00',\n",
       " '11th 14th',\n",
       " '11th 2001',\n",
       " '11th 2016',\n",
       " '11th 20th',\n",
       " '11th 7th',\n",
       " '11th accepting',\n",
       " '11th amp',\n",
       " '11th arrondissement',\n",
       " '11th baltimore',\n",
       " '11th centuries',\n",
       " '11th comandment',\n",
       " '11th commandment',\n",
       " '11th day',\n",
       " '11th forgotten',\n",
       " '11th going',\n",
       " '11th grade',\n",
       " '11th hmm',\n",
       " '11th hour',\n",
       " '11th http',\n",
       " '11th https',\n",
       " '11th include',\n",
       " '11th lifts',\n",
       " '11th like',\n",
       " '11th losing',\n",
       " '11th lost',\n",
       " '11th month',\n",
       " '11th niagara',\n",
       " '11th october',\n",
       " '11th open',\n",
       " '11th opened',\n",
       " '11th pick',\n",
       " '11th place',\n",
       " '11th player',\n",
       " '11th priced',\n",
       " '11th round',\n",
       " '11th sharknado',\n",
       " '11th shit',\n",
       " '11th sign',\n",
       " '11th sing',\n",
       " '11th singles',\n",
       " '11th sold',\n",
       " '11th tails',\n",
       " '11th taught',\n",
       " '11th td',\n",
       " '11th terrorists',\n",
       " '11th text',\n",
       " '11th theopen2015',\n",
       " '11th thinks',\n",
       " '11th time',\n",
       " '11th waiting',\n",
       " '11th war',\n",
       " '11th week',\n",
       " '11th year',\n",
       " '11th yelling',\n",
       " '11th yr',\n",
       " '11xexfdf83',\n",
       " '11xexfdf83 woeisme',\n",
       " '11yr',\n",
       " '11yr old',\n",
       " '12',\n",
       " '12 00',\n",
       " '12 000',\n",
       " '12 06',\n",
       " '12 08',\n",
       " '12 10',\n",
       " '12 100',\n",
       " '12 12',\n",
       " '12 13',\n",
       " '12 15',\n",
       " '12 17',\n",
       " '12 19',\n",
       " '12 1989',\n",
       " '12 2001',\n",
       " '12 2pm',\n",
       " '12 30',\n",
       " '12 30am',\n",
       " '12 30p',\n",
       " '12 30pm',\n",
       " '12 45pm',\n",
       " '12 50',\n",
       " '12 8p',\n",
       " '12 8th',\n",
       " '12 999',\n",
       " '12 9pm',\n",
       " '12 amctheatres',\n",
       " '12 amp',\n",
       " '12 april',\n",
       " '12 aug',\n",
       " '12 august',\n",
       " '12 bad',\n",
       " '12 bout',\n",
       " '12 boxing',\n",
       " '12 career',\n",
       " '12 character',\n",
       " '12 come',\n",
       " '12 comes',\n",
       " '12 curtis',\n",
       " '12 date',\n",
       " '12 david',\n",
       " '12 day',\n",
       " '12 days',\n",
       " '12 dec',\n",
       " '12 entering',\n",
       " '12 f4ntastic',\n",
       " '12 feet',\n",
       " '12 fight',\n",
       " '12 final',\n",
       " '12 floyd',\n",
       " '12 following',\n",
       " '12 friday',\n",
       " '12 games',\n",
       " '12 gaza',\n",
       " '12 going',\n",
       " '12 hours',\n",
       " '12 http',\n",
       " '12 https',\n",
       " '12 january',\n",
       " '12 jiffylubelive',\n",
       " '12 kcopher_3',\n",
       " '12 kendrick',\n",
       " '12 know',\n",
       " '12 lady',\n",
       " '12 ldcatlanta',\n",
       " '12 lead',\n",
       " '12 leader',\n",
       " '12 lol',\n",
       " '12 make',\n",
       " '12 mgm',\n",
       " '12 milan',\n",
       " '12 min',\n",
       " '12 monkeys',\n",
       " '12 months',\n",
       " '12 moto',\n",
       " '12 new',\n",
       " '12 noon',\n",
       " '12 obama',\n",
       " '12 odds',\n",
       " '12 paul',\n",
       " '12 people',\n",
       " '12 players',\n",
       " '12 pm',\n",
       " '12 poetic',\n",
       " '12 points',\n",
       " '12 possible',\n",
       " '12 professional',\n",
       " '12 rounds',\n",
       " '12 row',\n",
       " '12 runs',\n",
       " '12 sep',\n",
       " '12 september',\n",
       " '12 shawaal',\n",
       " '12 showdown',\n",
       " '12 spieth',\n",
       " '12 start',\n",
       " '12 straight',\n",
       " '12 street',\n",
       " '12 tied',\n",
       " '12 time',\n",
       " '12 today',\n",
       " '12 uk',\n",
       " '12 usa',\n",
       " '12 walker',\n",
       " '12 watch',\n",
       " '12 watching',\n",
       " '12 west',\n",
       " '12 wins',\n",
       " '12 yahweh',\n",
       " '12 yard',\n",
       " '12 year',\n",
       " '12 years',\n",
       " '12 yrs',\n",
       " '120',\n",
       " '120 000',\n",
       " '120 dbs',\n",
       " '120 good',\n",
       " '120 hmu',\n",
       " '120 paul',\n",
       " '120 rising',\n",
       " '120 tickets',\n",
       " '1200',\n",
       " '1200 yrs',\n",
       " '12000',\n",
       " '12000 contestants',\n",
       " '121',\n",
       " '121 22nd',\n",
       " '1237',\n",
       " '1237 june',\n",
       " '123nitin',\n",
       " '123nitin moto',\n",
       " '124',\n",
       " '124 brewery',\n",
       " '124rabbit',\n",
       " '124rabbit tonight',\n",
       " '125',\n",
       " '1250',\n",
       " '1250 vs',\n",
       " '128',\n",
       " '128 detainees',\n",
       " '129',\n",
       " '129 killed',\n",
       " '12999',\n",
       " '12999 9999',\n",
       " '12am',\n",
       " '12am 12',\n",
       " '12am cbb',\n",
       " '12noon',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to take a look at the features themselves, you can turn the sparse matrix object returned by the CountVectorizer into an array (this will be memory intensive, so you might get a memory error). Observe that most words just have zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training the NB classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a classifier in sklearn involves these steps:\n",
    "1. Initialising an instance of the MultinomialNB class\n",
    "2. Fitting the classifier (forcing it to learn parameters) to the training data with corresponding labels.\n",
    "\n",
    "Our training data is now <b>train_features</b>; the corresponding labels for each row are in the column <b>train['Polarity']</b>\n",
    "\n",
    "The code below uses the sklearn built-in NB classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Returns a fitter (trained) classifier\n",
    "nb_classifier = MultinomialNB().fit(train_features, train['Polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Testing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can apply our classifier, we need to also perform the same vectorization operations on the test set. However, we do not call fit_transform(), but only transform(). This is because the CountVectorizer has already been fit to our training data. We only want to extract the known features from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = counter.transform(test['Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to apply it to the test data. This returns an array of predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb_classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I may be mean with niall's legs sometimes but it doesnt mean i dont care\" => neutral - 'neutral'\n"
     ]
    }
   ],
   "source": [
    "#What is the prediction for the first tweet?\n",
    "print('%r => %s - %r' % (test['Tweet'].iloc[0], predictions[0], test['Polarity'].iloc[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tfidf Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18568, 175925)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(train_features)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train_features, train['Polarity'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love, God is life', 'I want to die, life is shit, somebody kill me', 'I am a stupid boy who likes to play in the mud','Existence is shallow, there is no purpose, life has no meaning']\n",
    "X_new_counts = counter.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1st SCOTUS pisses off Christians with gay marriage LAW then rightly jails #kimdavies for breaking it ! #bravo https://t.co/nFE1qXe1s3' => negative - 'neutral'\n"
     ]
    }
   ],
   "source": [
    "print('%r => %s - %r' % (test['Tweet'].iloc[348], predicted2[348], test['Polarity'].iloc[348]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Evaluation\n",
    "Finally, we can look at some evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.17      0.28       308\n",
      "     neutral       0.61      0.80      0.70      1036\n",
      "    positive       0.65      0.57      0.61       720\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      2064\n",
      "   macro avg       0.65      0.51      0.53      2064\n",
      "weighted avg       0.64      0.63      0.60      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test['Polarity'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\">confusion matrix</a> to see which categories tend to be confused with each other. Note that rows and columns are ordered alphabetically by label (negative, neutral, positive) so that, e.g. row 0 column 1 is the number of times the first class (negative) is mislabelled as the second (neutral). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53 215  40]\n",
      " [ 20 831 185]\n",
      " [  3 307 410]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test['Polarity'], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
