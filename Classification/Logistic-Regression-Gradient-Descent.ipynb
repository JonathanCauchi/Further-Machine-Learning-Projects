{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[1:7]].values\n",
    "y = data['Research'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337.   118.     4.     4.5    4.5    9.65]\n",
      " [324.   107.     4.     4.     4.5    8.87]\n",
      " [316.   104.     3.     3.     3.5    8.  ]\n",
      " ...\n",
      " [330.   116.     4.     5.     4.5    9.45]\n",
      " [312.   103.     3.     3.5    4.     8.78]\n",
      " [333.   117.     4.     5.     4.     9.66]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
      " 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1\n",
      " 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 6) (80, 6) (320,) (80,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X, y, split=0.2):\n",
    "    indices = np.random.permutation(X.shape[0]) ## X.shape[0] == rows of data which is equal to 400. we are going to shuffle our data to prevent overfitting and to normalize our data\n",
    "    # it would be ideal to shuffle data cause some data might already be sorted by their classification, the model might pick on this and overfit\n",
    "    split = int(split * X.shape[0])\n",
    "\n",
    "    train_indices = indices[split:]\n",
    "    test_indices = indices[:split]\n",
    "\n",
    "    x_train, x_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(X, y)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the structure of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,lr=0.01,num_iter=100):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        \n",
    "    def predict(self, X):## given the array/features we pass, we will be given a predicted output\n",
    "        X = self.normalize(X)\n",
    "        linear = self.__linear(X)\n",
    "        preds = self.non_linear(linear)\n",
    "        return (preds >= 0.5).astype('int') ## 0.5 is the decision boundary\n",
    "        \n",
    "    def __linear(self,X):#2nd step\n",
    "        ## linear regression, applied weights to the sum and then will be passed to the sigmoid function which will then be passed on to prediction\n",
    "        ## now that we initialized our weights, we can proceed to dot product X with w then we add the bias\n",
    "        return np.dot(X,self.weights) + self.bias\n",
    "    \n",
    "    def non_linear(self,X):##3rd step, sigmoid function\n",
    "        return (1/1+np.exp(-X))\n",
    "    \n",
    "    def fit(self, x_train, y_train):##we fit our X & Y features and appply gradient descent, the weights will be adjusted after each step\n",
    "        self.init_weights(x_train)\n",
    "        \n",
    "        ## https://www.statisticshowto.datasciencecentral.com/normalized/\n",
    "        self.X_mean = x_train.mean().T\n",
    "        self.X_std = y_train.std().T\n",
    "        \n",
    "        ## we normalize our data before starting gradient descent\n",
    "        x_train = self.normalize(x_train)\n",
    "        \n",
    "        for i in range (self.num_iter):\n",
    "            \n",
    "            work = self.non_linear(self.__linear(x_train))\n",
    "            gradient = work - y_train\n",
    "            \n",
    "            delta_w = np.mean(np.dot(gradient,x_train), axis=0, keepdims=True).T\n",
    "            delta_b = np.mean(gradient)\n",
    "\n",
    "            # update weights\n",
    "            self.weights = self.weights - (self.lr * delta_w)\n",
    "            self.bias = self.bias - (self.lr * delta_b)\n",
    "        return self\n",
    "                 \n",
    "        \n",
    "    def accuracy(self, X, y):## to calculate the accuracy of our model, it is equal to the mean of correct predictions\n",
    "        preds = self.predict(X)\n",
    "        return np.mean(preds == y)\n",
    "    \n",
    "        \n",
    "    def normalize(self, X): ## we need to constantly shuffle our data during each step of gradient descent, \n",
    "        ## formula is equal to; x = x - mean of x/ std of x given (x1,x2...xn)\n",
    "        X = (X - (self.X_mean)) / self.X_std ## we are standardizing our data\n",
    "        return X\n",
    "        \n",
    "        \n",
    "    def init_weights(self,X):#1st step\n",
    "        self.weights = np.random.rand(X.shape[1],1) ## this will generate a (6x1) matrix. So when we will grab the input data of a  (400X6) matrix, when multiplied with the weights it will become a (400X1) matrix\n",
    "        self.bias = np.zeros((1,)) ## bias set to 0 \n",
    "\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        probs = self.non_linear(self.__linear(X))\n",
    "\n",
    "        # entropy when true class is positive\n",
    "        pos_log = y * np.log(probs + 1e-15)\n",
    "        # entropy when true class is negative\n",
    "        neg_log = (1 - y) * np.log((1 - probs) + 1e-15)\n",
    "\n",
    "        l = -np.mean(pos_log + neg_log)\n",
    "        return l\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x27871647978>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 51.25%\n",
      "Loss on test set: nan\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test set: {:.2f}%'.format(lr.accuracy(x_test, y_test) * 100))\n",
    "print('Loss on test set: {:.2f}'.format(lr.loss(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see from above, the loss result came out as NaN and the accuracy is not that great. This could come down either because the model overfitted the data and it needs to be normalized or the learning rate is too large. In this case, the learning rate is alright and we did standardize the data when fitting our model. So yeah, im not sure but its fun to think about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sklearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[data.columns[1:7]].values\n",
    "y = data['Research'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.predict(x_test[0].reshape(1,-1))\n",
    "predictions = lr.predict(x_test)\n",
    "score = lr.score(X_test, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
