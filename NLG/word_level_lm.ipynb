{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_level_lm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5U6cy6_r5qFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "import pandas as pd\n",
        "\n",
        "sequence_length=1\n",
        "\n",
        "# define the model\n",
        "def define_model(vocab_size,max_length):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
        "\tmodel.add(LSTM(50))\n",
        "\tmodel.add(Dense(vocab_size, activation='softmax'))\n",
        "\t# compile network\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# summarize defined model\n",
        "\tmodel.summary()\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model\n",
        "\n",
        "# generate a sequence from a language model\n",
        "def generate_text(model, tokenizer, max_length, seed_text, n_words):\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pre-pad sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded,verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\treturn in_text\n",
        "\n",
        "\n",
        "# framing language modelling\n",
        "def frame_lm(encoded, length):\n",
        "  sequences = list()\n",
        "  for i in range(length, len(encoded)):\n",
        "    sequence = encoded[i-length:i+1]\n",
        "    sequences.append(sequence)\n",
        "  return sequences\n",
        "\n",
        "# source text\n",
        "data = \"\"\" Jack and Jill went up the hill\\n\n",
        "\t\tTo fetch a pail of water\\n\n",
        "\t\tJack fell down and broke his crown\\n\n",
        "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded = tokenizer.texts_to_sequences([data])[0]\n",
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "\n",
        "sequences=frame_lm(encoded,sequence_length)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "max_length=max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences,maxlen=max_length,padding='pre')\n",
        "print('Max Sequence Length: %d' %max_length)\n",
        "# split into X and y elements\n",
        "sequences = array(sequences)\n",
        "#all columns except last go into X and the last columns goes into y\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "print(y.shape)\n",
        "# define model\n",
        "model = define_model(vocab_size,max_length)\n",
        "# fit network\n",
        "model.fit(X, y, epochs=500, verbose=2)\n",
        "# evaluate\n",
        "print(generate_text(model, tokenizer, max_length-1,'Jack and Jill', 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrzeF0ljhNTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}